--------------------------------------------------------
--------------------------------------------------------
                                                 <strong>         niState          </strong>
                                                 <strong>__________________________</strong>

    <strong>wp2dataCreation.fsHz</strong>                         '44100'                   
    <strong>wp2dataCreation.nErbs</strong>                        '1'                       
    <strong>wp2dataCreation.nChannels</strong>                    '32'                      
    <strong>wp2dataCreation.mEarF</strong>                        'true'                    
    <strong>wp2dataCreation.fLowHz</strong>                       '80'                      
    <strong>wp2dataCreation.fHighHz</strong>                      '8000'                    
    <strong>wp2dataCreation.ihcMethod</strong>                    'halfwave'                
    <strong>wp2dataCreation.winSizeSec</strong>                   '0.02'                    
    <strong>wp2dataCreation.hopSizeSec</strong>                   '0.01'                    
    <strong>wp2dataCreation.winType</strong>                      'hann'                    
    <strong>wp2dataCreation.bNormRMS</strong>                     'false'                   
    <strong>wp2dataCreation.bAlign</strong>                       'false'                   
    <strong>wp2dataCreation.maxDelaySec</strong>                  '0.001'                   
    <strong>wp2dataCreation.strCues</strong>                      'ratemap_magnitude'       
    <strong>wp2dataCreation.strFeatures</strong>                  {}                        
    <strong>wp2dataCreation.angle</strong>                        '0'                       
    <strong>wp2dataCreation.head</strong>                         'QU_KEMAR_anechoic_3m.mat'
    <strong>blockCreation.blockSize</strong>                      '0.5'                     
    <strong>blockCreation.shiftSize</strong>                      '0.25'                    
    <strong>Labeling.minBlockToEventRatio</strong>                '0.8'                     
    <strong>featureCreation.function</strong>                     'msFeatures'              
    <strong>featureCreation.functionParam.derivations</strong>    '1'                       
    <strong>hyperParamSearch.epsilons</strong>                    '0.001'                   
    <strong>hyperParamSearch.cRange</strong>                      '[-5 5]'                  
    <strong>hyperParamSearch.gammaRange</strong>                  '[-12 3]'                 
    <strong>hyperParamSearch.kernels</strong>                     '0'                       
    <strong>hyperParamSearch.method</strong>                      'grid'                    
    <strong>hyperParamSearch.searchBudget</strong>                '9'                       
    <strong>hyperParamSearch.dataShare</strong>                   '1'                       
    <strong>hyperParamSearch.refineStages</strong>                '0'                       
    <strong>hyperParamSearch.folds</strong>                       '4'                       
    <strong>generalizationEstimation.folds</strong>               '4'                       

--------------------------------------------------------
wp2 processing of sounds
.................................................................................................................................................................................................................................................................................;
blockifying data
.................................................................................................................................................................................................................................................................................;
make labels .................................................................................................................................................................................................................................................................................;
make features;
splitting data into training/test folds.
........

1. run of generalization assessment CV -- training

grid search for best hyperparameters


CV with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 8.533333e+01 -q -e 1.000000e-03
training performance:
Accuracy = 89.3436% (1157/1295) (classification)
BAC = 0.748437 (Sens = 0.6, Spec = 0.896875)
testing performance:
Accuracy = 85.7939% (308/359) (classification)
BAC = 0.730791 (Sens = 0.6, Spec = 0.861582)
training with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 8.807692e+01 -q -e 1.000000e-03
training performance:
Accuracy = 90.7599% (1051/1158) (classification)
BAC = 0.839201 (Sens = 0.769231, Spec = 0.90917)
testing performance:
Accuracy = 92.3387% (458/496) (classification)
BAC = 0.679521 (Sens = 0.428571, Spec = 0.93047)
training with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 7.937500e+01 -q -e 1.000000e-03
training performance:
Accuracy = 90.2022% (1160/1286) (classification)
BAC = 0.796112 (Sens = 0.6875, Spec = 0.904724)
testing performance:
Accuracy = 89.4022% (329/368) (classification)
BAC = 0.699176 (Sens = 0.5, Spec = 0.898352)
training with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 7.543750e+01 -q -e 1.000000e-03
training performance:
Accuracy = 74.9796% (917/1223) (classification)
BAC = 0.842404 (Sens = 0.9375, Spec = 0.747307)
testing performance:
Accuracy = 78.4223% (338/431) (classification)
BAC = 0.891101 (Sens = 1, Spec = 0.782201)
Average training performance after CV: 0.806538
Average generalization performance after CV: 0.750147

CV with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 9.346154e+01 -q -e 1.000000e-03
training performance:
Accuracy = 88.8436% (1091/1228) (classification)
BAC = 0.943621 (Sens = 1, Spec = 0.887243)
testing performance:
Accuracy = 86.385% (368/426) (classification)
BAC = 0.860552 (Sens = 0.857143, Spec = 0.863962)
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 7.760000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 85.4962% (1008/1179) (classification)
BAC = 0.926546 (Sens = 1, Spec = 0.853093)
testing performance:
Accuracy = 86.3158% (410/475) (classification)
BAC = 0.930851 (Sens = 1, Spec = 0.861702)
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 7.400000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 87.2157% (1112/1275) (classification)
BAC = 0.935215 (Sens = 1, Spec = 0.870429)
testing performance:
Accuracy = 84.1689% (319/379) (classification)
BAC = 0.920213 (Sens = 1, Spec = 0.840426)
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 8.433333e+01 -q -e 1.000000e-03
training performance:
Accuracy = 86.3281% (1105/1280) (classification)
BAC = 0.93083 (Sens = 1, Spec = 0.86166)
testing performance:
Accuracy = 88.2353% (330/374) (classification)
BAC = 0.841734 (Sens = 0.8, Spec = 0.883469)
Average training performance after CV: 0.934053
Average generalization performance after CV: 0.888338

CV with -t 0 -g 0.000000e+00 -c 3.162278e-03 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 3.162278e-03 -w-1 1 -w1 9.142857e+01 -q -e 1.000000e-03
training performance:
Accuracy = 96.5997% (1250/1294) (classification)
BAC = 0.982812 (Sens = 1, Spec = 0.965625)
testing performance:
Accuracy = 92.5% (333/360) (classification)
BAC = 0.798023 (Sens = 0.666667, Spec = 0.929379)
training with -t 0 -g 0.000000e+00 -c 3.162278e-03 -w-1 1 -w1 7.766667e+01 -q -e 1.000000e-03
training performance:
Accuracy = 95.9322% (1132/1180) (classification)
BAC = 0.979399 (Sens = 1, Spec = 0.958798)
testing performance:
Accuracy = 95.5696% (453/474) (classification)
BAC = 0.68081 (Sens = 0.4, Spec = 0.96162)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.990553
Average generalization performance after CV: 0.869708

CV with -t 0 -g 0.000000e+00 -c 5.623413e-02 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 5.623413e-02 -w-1 1 -w1 7.366667e+01 -q -e 1.000000e-03
training performance:
Accuracy = 98.2143% (1100/1120) (classification)
BAC = 0.99095 (Sens = 1, Spec = 0.9819)
testing performance:
Accuracy = 96.2547% (514/534) (classification)
BAC = 0.584877 (Sens = 0.2, Spec = 0.969754)
training with -t 0 -g 0.000000e+00 -c 5.623413e-02 -w-1 1 -w1 8.446667e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.142% (1271/1282) (classification)
BAC = 0.995659 (Sens = 1, Spec = 0.991318)
testing performance:
Accuracy = 97.043% (361/372) (classification)
BAC = 0.491826 (Sens = 0, Spec = 0.983651)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.996652
Average generalization performance after CV: 0.769176

CV with -t 0 -g 0.000000e+00 -c 1.000000e+00 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.000000e+00 -w-1 1 -w1 8.046667e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.4272% (1215/1222) (classification)
BAC = 0.9971 (Sens = 1, Spec = 0.9942)
testing performance:
Accuracy = 92.5926% (400/432) (classification)
BAC = 0.567213 (Sens = 0.2, Spec = 0.934426)
training with -t 0 -g 0.000000e+00 -c 1.000000e+00 -w-1 1 -w1 7.875000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.6082% (1271/1276) (classification)
BAC = 0.998016 (Sens = 1, Spec = 0.996032)
testing performance:
Accuracy = 96.8254% (366/378) (classification)
BAC = 0.489305 (Sens = 0, Spec = 0.97861)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.998779
Average generalization performance after CV: 0.764129

CV with -t 0 -g 0.000000e+00 -c 1.778279e+01 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.778279e+01 -w-1 1 -w1 9.461538e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.5173% (1237/1243) (classification)
BAC = 0.997561 (Sens = 1, Spec = 0.995122)
testing performance:
Accuracy = 98.0535% (403/411) (classification)
BAC = 0.498762 (Sens = 0, Spec = 0.997525)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.99939
Average generalization performance after CV: 0.874691

CV with -t 0 -g 0.000000e+00 -c 3.162278e+02 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 3.162278e+02 -w-1 1 -w1 7.893333e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.4162% (1192/1199) (classification)
BAC = 0.997044 (Sens = 1, Spec = 0.994088)
testing performance:
Accuracy = 97.1429% (442/455) (classification)
BAC = 0.491111 (Sens = 0, Spec = 0.982222)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.999261
Average generalization performance after CV: 0.872778

CV with -t 0 -g 0.000000e+00 -c 5.623413e+03 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 5.623413e+03 -w-1 1 -w1 8.935714e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.5257% (1259/1265) (classification)
BAC = 0.997602 (Sens = 1, Spec = 0.995204)
testing performance:
Accuracy = 97.4293% (379/389) (classification)
BAC = 0.494778 (Sens = 0, Spec = 0.989556)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.9994
Average generalization performance after CV: 0.873695

CV with -t 0 -g 0.000000e+00 -c 1.000000e+05 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.000000e+05 -w-1 1 -w1 7.700000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.4872% (1164/1170) (classification)
BAC = 0.997403 (Sens = 1, Spec = 0.994805)
testing performance:
Accuracy = 96.0744% (465/484) (classification)
BAC = 0.584342 (Sens = 0.2, Spec = 0.968685)
training with -t 0 -g 0.000000e+00 -c 1.000000e+05 -w-1 1 -w1 8.293333e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.6823% (1255/1259) (classification)
BAC = 0.998392 (Sens = 1, Spec = 0.996785)
testing performance:
Accuracy = 96.4557% (381/395) (classification)
BAC = 0.488462 (Sens = 0, Spec = 0.976923)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.998949
Average generalization performance after CV: 0.768201

training with best hyperparameters (CV gen prediction: 0.888338)
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 8.190000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 87.4548% (1450/1658) (classification)
BAC = 0.936508 (Sens = 1, Spec = 0.873016)

1. run of generalization assessment CV -- testing
Accuracy = 88.1188% (534/606) (classification)
BAC = 0.94 (Sens = 1, Spec = 0.88)

2. run of generalization assessment CV -- training

grid search for best hyperparameters


CV with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 9.250000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 84.1864% (1102/1309) (classification)
BAC = 0.849421 (Sens = 0.857143, Spec = 0.841699)
testing performance:
Accuracy = 84.7875% (379/447) (classification)
BAC = 0.840703 (Sens = 0.833333, Spec = 0.848073)
training with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 9.166667e+01 -q -e 1.000000e-03
training performance:
Accuracy = 83.9568% (1167/1390) (classification)
BAC = 0.885939 (Sens = 0.933333, Spec = 0.838545)
testing performance:
Accuracy = 80.3279% (294/366) (classification)
BAC = 0.604432 (Sens = 0.4, Spec = 0.808864)
training with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 7.464706e+01 -q -e 1.000000e-03
training performance:
Accuracy = 88.3359% (1136/1286) (classification)
BAC = 0.824827 (Sens = 0.764706, Spec = 0.884949)
testing performance:
Accuracy = 87.6596% (412/470) (classification)
BAC = 0.937901 (Sens = 1, Spec = 0.875803)
training with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 9.064286e+01 -q -e 1.000000e-03
training performance:
Accuracy = 91.8161% (1178/1283) (classification)
BAC = 0.782027 (Sens = 0.642857, Spec = 0.921198)
testing performance:
Accuracy = 91.9662% (435/473) (classification)
BAC = 0.877052 (Sens = 0.833333, Spec = 0.920771)
Average training performance after CV: 0.835554
Average generalization performance after CV: 0.815022

CV with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 8.866667e+01 -q -e 1.000000e-03
training performance:
Accuracy = 89.8885% (1209/1345) (classification)
BAC = 0.948872 (Sens = 1, Spec = 0.897744)
testing performance:
Accuracy = 89.2944% (367/411) (classification)
BAC = 0.649507 (Sens = 0.4, Spec = 0.899015)
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 8.733333e+01 -q -e 1.000000e-03
training performance:
Accuracy = 86.4906% (1146/1325) (classification)
BAC = 0.931679 (Sens = 1, Spec = 0.863359)
testing performance:
Accuracy = 84.6868% (365/431) (classification)
BAC = 0.922535 (Sens = 1, Spec = 0.84507)
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 8.686667e+01 -q -e 1.000000e-03
training performance:
Accuracy = 85.8877% (1132/1318) (classification)
BAC = 0.928626 (Sens = 1, Spec = 0.857252)
testing performance:
Accuracy = 85.8447% (376/438) (classification)
BAC = 0.928406 (Sens = 1, Spec = 0.856813)
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 8.433333e+01 -q -e 1.000000e-03
training performance:
Accuracy = 90% (1152/1280) (classification)
BAC = 0.949407 (Sens = 1, Spec = 0.898814)
testing performance:
Accuracy = 91.5966% (436/476) (classification)
BAC = 0.858599 (Sens = 0.8, Spec = 0.917197)
Average training performance after CV: 0.939646
Average generalization performance after CV: 0.839762

CV with -t 0 -g 0.000000e+00 -c 3.162278e-03 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 3.162278e-03 -w-1 1 -w1 7.852941e+01 -q -e 1.000000e-03
training performance:
Accuracy = 94.8225% (1282/1352) (classification)
BAC = 0.973783 (Sens = 1, Spec = 0.947566)
testing performance:
Accuracy = 90.8416% (367/404) (classification)
BAC = 0.953865 (Sens = 1, Spec = 0.907731)
training with -t 0 -g 0.000000e+00 -c 3.162278e-03 -w-1 1 -w1 8.043750e+01 -q -e 1.000000e-03
training performance:
Accuracy = 94.9348% (1237/1303) (classification)
BAC = 0.974359 (Sens = 1, Spec = 0.948718)
testing performance:
Accuracy = 94.4812% (428/453) (classification)
BAC = 0.848274 (Sens = 0.75, Spec = 0.946548)
training with -t 0 -g 0.000000e+00 -c 3.162278e-03 -w-1 1 -w1 9.776923e+01 -q -e 1.000000e-03
training performance:
Accuracy = 96.9626% (1245/1284) (classification)
BAC = 0.984658 (Sens = 1, Spec = 0.969315)
testing performance:
Accuracy = 96.822% (457/472) (classification)
BAC = 0.632104 (Sens = 0.285714, Spec = 0.978495)
training with -t 0 -g 0.000000e+00 -c 3.162278e-03 -w-1 1 -w1 9.392857e+01 -q -e 1.000000e-03
training performance:
Accuracy = 96.614% (1284/1329) (classification)
BAC = 0.98289 (Sens = 1, Spec = 0.965779)
testing performance:
Accuracy = 96.0187% (410/427) (classification)
BAC = 0.733373 (Sens = 0.5, Spec = 0.966746)
Average training performance after CV: 0.978922
Average generalization performance after CV: 0.791904

CV with -t 0 -g 0.000000e+00 -c 5.623413e-02 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 5.623413e-02 -w-1 1 -w1 9.221429e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.3103% (1296/1305) (classification)
BAC = 0.996514 (Sens = 1, Spec = 0.993029)
testing performance:
Accuracy = 97.561% (440/451) (classification)
BAC = 0.494382 (Sens = 0, Spec = 0.988764)
training with -t 0 -g 0.000000e+00 -c 5.623413e-02 -w-1 1 -w1 8.466667e+01 -q -e 1.000000e-03
training performance:
Accuracy = 98.677% (1268/1285) (classification)
BAC = 0.993307 (Sens = 1, Spec = 0.986614)
testing performance:
Accuracy = 97.4522% (459/471) (classification)
BAC = 0.591416 (Sens = 0.2, Spec = 0.982833)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.997455
Average generalization performance after CV: 0.77145

CV with -t 0 -g 0.000000e+00 -c 1.000000e+00 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.000000e+00 -w-1 1 -w1 8.381250e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.7789% (1354/1357) (classification)
BAC = 0.998881 (Sens = 1, Spec = 0.997763)
testing performance:
Accuracy = 96.4912% (385/399) (classification)
BAC = 0.487342 (Sens = 0, Spec = 0.974684)
training with -t 0 -g 0.000000e+00 -c 1.000000e+00 -w-1 1 -w1 9.078571e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.6109% (1280/1285) (classification)
BAC = 0.998033 (Sens = 1, Spec = 0.996066)
testing performance:
Accuracy = 98.5138% (464/471) (classification)
BAC = 0.745699 (Sens = 0.5, Spec = 0.991398)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.999229
Average generalization performance after CV: 0.80826

CV with -t 0 -g 0.000000e+00 -c 1.778279e+01 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.778279e+01 -w-1 1 -w1 7.643750e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.8386% (1237/1239) (classification)
BAC = 0.999182 (Sens = 1, Spec = 0.998365)
testing performance:
Accuracy = 97.2921% (503/517) (classification)
BAC = 0.614279 (Sens = 0.25, Spec = 0.978558)
training with -t 0 -g 0.000000e+00 -c 1.778279e+01 -w-1 1 -w1 1.090833e+02 -q -e 1.000000e-03
training performance:
Accuracy = 99.6972% (1317/1321) (classification)
BAC = 0.998472 (Sens = 1, Spec = 0.996944)
testing performance:
Accuracy = 97.2414% (423/435) (classification)
BAC = 0.556645 (Sens = 0.125, Spec = 0.98829)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.999414
Average generalization performance after CV: 0.792731

CV with -t 0 -g 0.000000e+00 -c 3.162278e+02 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 3.162278e+02 -w-1 1 -w1 9.292857e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.6958% (1311/1315) (classification)
BAC = 0.998463 (Sens = 1, Spec = 0.996925)
testing performance:
Accuracy = 96.5986% (426/441) (classification)
BAC = 0.571839 (Sens = 0.166667, Spec = 0.977011)
training with -t 0 -g 0.000000e+00 -c 3.162278e+02 -w-1 1 -w1 8.018750e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.5381% (1293/1299) (classification)
BAC = 0.997662 (Sens = 1, Spec = 0.995323)
testing performance:
Accuracy = 96.9365% (443/457) (classification)
BAC = 0.612859 (Sens = 0.25, Spec = 0.975717)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.999031
Average generalization performance after CV: 0.796174

CV with -t 0 -g 0.000000e+00 -c 5.623413e+03 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 5.623413e+03 -w-1 1 -w1 8.606250e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.6411% (1388/1393) (classification)
BAC = 0.998184 (Sens = 1, Spec = 0.996369)
testing performance:
Accuracy = 96.9697% (352/363) (classification)
BAC = 0.490251 (Sens = 0, Spec = 0.980501)
training with -t 0 -g 0.000000e+00 -c 5.623413e+03 -w-1 1 -w1 9.000000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.6337% (1360/1365) (classification)
BAC = 0.998148 (Sens = 1, Spec = 0.996296)
testing performance:
Accuracy = 96.6752% (378/391) (classification)
BAC = 0.588342 (Sens = 0.2, Spec = 0.976684)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.999083
Average generalization performance after CV: 0.769648

CV with -t 0 -g 0.000000e+00 -c 1.000000e+05 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.000000e+05 -w-1 1 -w1 1.006154e+02 -q -e 1.000000e-03
training performance:
Accuracy = 99.6215% (1316/1321) (classification)
BAC = 0.998089 (Sens = 1, Spec = 0.996177)
testing performance:
Accuracy = 98.1609% (427/435) (classification)
BAC = 0.498832 (Sens = 0, Spec = 0.997664)
training with -t 0 -g 0.000000e+00 -c 1.000000e+05 -w-1 1 -w1 9.500000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.8512% (1342/1344) (classification)
BAC = 0.999248 (Sens = 1, Spec = 0.998496)
testing performance:
Accuracy = 96.8447% (399/412) (classification)
BAC = 0.655583 (Sens = 0.333333, Spec = 0.977833)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.999334
Average generalization performance after CV: 0.788604

training with best hyperparameters (CV gen prediction: 0.839762)
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 8.700000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 88.8068% (1563/1760) (classification)
BAC = 0.943391 (Sens = 1, Spec = 0.886782)

2. run of generalization assessment CV -- testing
Accuracy = 86.7063% (437/504) (classification)
BAC = 0.932731 (Sens = 1, Spec = 0.865462)

3. run of generalization assessment CV -- training

grid search for best hyperparameters


CV with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 9.600000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 88.7391% (1119/1261) (classification)
BAC = 0.866987 (Sens = 0.846154, Spec = 0.887821)
testing performance:
Accuracy = 85.7143% (366/427) (classification)
BAC = 0.598971 (Sens = 0.333333, Spec = 0.864608)
training with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 8.480000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 87.1795% (1122/1287) (classification)
BAC = 0.803381 (Sens = 0.733333, Spec = 0.873428)
testing performance:
Accuracy = 89.7756% (360/401) (classification)
BAC = 0.824622 (Sens = 0.75, Spec = 0.899244)
training with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 7.843750e+01 -q -e 1.000000e-03
training performance:
Accuracy = 93.4697% (1188/1271) (classification)
BAC = 0.750971 (Sens = 0.5625, Spec = 0.939442)
testing performance:
Accuracy = 92.8058% (387/417) (classification)
BAC = 0.963768 (Sens = 1, Spec = 0.927536)
training with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 9.476923e+01 -q -e 1.000000e-03
training performance:
Accuracy = 92.9317% (1157/1245) (classification)
BAC = 0.774007 (Sens = 0.615385, Spec = 0.93263)
testing performance:
Accuracy = 93.4537% (414/443) (classification)
BAC = 0.802441 (Sens = 0.666667, Spec = 0.938215)
Average training performance after CV: 0.798837
Average generalization performance after CV: 0.79745

CV with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 9.715385e+01 -q -e 1.000000e-03
training performance:
Accuracy = 87.5392% (1117/1276) (classification)
BAC = 0.937055 (Sens = 1, Spec = 0.874109)
testing performance:
Accuracy = 88.835% (366/412) (classification)
BAC = 0.861248 (Sens = 0.833333, Spec = 0.889163)
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 8.957143e+01 -q -e 1.000000e-03
training performance:
Accuracy = 86.3565% (1095/1268) (classification)
BAC = 0.931021 (Sens = 1, Spec = 0.862041)
testing performance:
Accuracy = 87.381% (367/420) (classification)
BAC = 0.936145 (Sens = 1, Spec = 0.872289)
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 7.912500e+01 -q -e 1.000000e-03
training performance:
Accuracy = 90.4836% (1160/1282) (classification)
BAC = 0.951817 (Sens = 1, Spec = 0.903633)
testing performance:
Accuracy = 89.9015% (365/406) (classification)
BAC = 0.783706 (Sens = 0.666667, Spec = 0.900744)
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 8.742857e+01 -q -e 1.000000e-03
training performance:
Accuracy = 87.4798% (1083/1238) (classification)
BAC = 0.936683 (Sens = 1, Spec = 0.873366)
testing performance:
Accuracy = 86.4444% (389/450) (classification)
BAC = 0.931461 (Sens = 1, Spec = 0.862921)
Average training performance after CV: 0.939144
Average generalization performance after CV: 0.87814

CV with -t 0 -g 0.000000e+00 -c 3.162278e-03 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 3.162278e-03 -w-1 1 -w1 8.440000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 96.1749% (1232/1281) (classification)
BAC = 0.980648 (Sens = 1, Spec = 0.961295)
testing performance:
Accuracy = 96.8059% (394/407) (classification)
BAC = 0.860112 (Sens = 0.75, Spec = 0.970223)
training with -t 0 -g 0.000000e+00 -c 3.162278e-03 -w-1 1 -w1 9.064286e+01 -q -e 1.000000e-03
training performance:
Accuracy = 96.9602% (1244/1283) (classification)
BAC = 0.984634 (Sens = 1, Spec = 0.969267)
testing performance:
Accuracy = 94.321% (382/405) (classification)
BAC = 0.8725 (Sens = 0.8, Spec = 0.945)
training with -t 0 -g 0.000000e+00 -c 3.162278e-03 -w-1 1 -w1 7.481250e+01 -q -e 1.000000e-03
training performance:
Accuracy = 96.0429% (1165/1213) (classification)
BAC = 0.97995 (Sens = 1, Spec = 0.9599)
testing performance:
Accuracy = 95.3684% (453/475) (classification)
BAC = 0.811088 (Sens = 0.666667, Spec = 0.955508)
training with -t 0 -g 0.000000e+00 -c 3.162278e-03 -w-1 1 -w1 1.062500e+02 -q -e 1.000000e-03
training performance:
Accuracy = 96.9697% (1248/1287) (classification)
BAC = 0.984706 (Sens = 1, Spec = 0.969412)
testing performance:
Accuracy = 94.015% (377/401) (classification)
BAC = 0.688905 (Sens = 0.428571, Spec = 0.949239)
Average training performance after CV: 0.982484
Average generalization performance after CV: 0.808151

CV with -t 0 -g 0.000000e+00 -c 5.623413e-02 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 5.623413e-02 -w-1 1 -w1 1.001538e+02 -q -e 1.000000e-03
training performance:
Accuracy = 99.6958% (1311/1315) (classification)
BAC = 0.998464 (Sens = 1, Spec = 0.996928)
testing performance:
Accuracy = 97.0509% (362/373) (classification)
BAC = 0.575159 (Sens = 0.166667, Spec = 0.983651)
training with -t 0 -g 0.000000e+00 -c 5.623413e-02 -w-1 1 -w1 8.433333e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.375% (1272/1280) (classification)
BAC = 0.996838 (Sens = 1, Spec = 0.993676)
testing performance:
Accuracy = 97.0588% (396/408) (classification)
BAC = 0.613861 (Sens = 0.25, Spec = 0.977723)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.998825
Average generalization performance after CV: 0.797255

CV with -t 0 -g 0.000000e+00 -c 1.000000e+00 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.000000e+00 -w-1 1 -w1 8.426667e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.7654% (1276/1279) (classification)
BAC = 0.998813 (Sens = 1, Spec = 0.997627)
testing performance:
Accuracy = 97.3105% (398/409) (classification)
BAC = 0.615123 (Sens = 0.25, Spec = 0.980247)
training with -t 0 -g 0.000000e+00 -c 1.000000e+00 -w-1 1 -w1 8.942857e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.763% (1263/1266) (classification)
BAC = 0.998802 (Sens = 1, Spec = 0.997604)
testing performance:
Accuracy = 97.8673% (413/422) (classification)
BAC = 0.791607 (Sens = 0.6, Spec = 0.983213)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.999404
Average generalization performance after CV: 0.851683

CV with -t 0 -g 0.000000e+00 -c 1.778279e+01 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.778279e+01 -w-1 1 -w1 9.178571e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.7691% (1296/1299) (classification)
BAC = 0.998833 (Sens = 1, Spec = 0.997665)
testing performance:
Accuracy = 98.4576% (383/389) (classification)
BAC = 0.498698 (Sens = 0, Spec = 0.997396)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.999708
Average generalization performance after CV: 0.874674

CV with -t 0 -g 0.000000e+00 -c 3.162278e+02 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 3.162278e+02 -w-1 1 -w1 8.593333e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.7699% (1301/1304) (classification)
BAC = 0.998836 (Sens = 1, Spec = 0.997673)
testing performance:
Accuracy = 98.9583% (380/384) (classification)
BAC = 0.871053 (Sens = 0.75, Spec = 0.992105)
training with -t 0 -g 0.000000e+00 -c 3.162278e+02 -w-1 1 -w1 8.721429e+01 -q -e 1.000000e-03
training performance:
Accuracy = 100% (1235/1235) (classification)
BAC = 1 (Sens = 1, Spec = 1)
testing performance:
Accuracy = 98.0132% (444/453) (classification)
BAC = 0.495536 (Sens = 0, Spec = 0.991071)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.999709
Average generalization performance after CV: 0.841647

CV with -t 0 -g 0.000000e+00 -c 5.623413e+03 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 5.623413e+03 -w-1 1 -w1 8.360000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.7636% (1266/1269) (classification)
BAC = 0.998804 (Sens = 1, Spec = 0.997608)
testing performance:
Accuracy = 98.568% (413/419) (classification)
BAC = 0.868976 (Sens = 0.75, Spec = 0.987952)
training with -t 0 -g 0.000000e+00 -c 5.623413e+03 -w-1 1 -w1 7.818750e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.7632% (1264/1267) (classification)
BAC = 0.998801 (Sens = 1, Spec = 0.997602)
testing performance:
Accuracy = 98.3373% (414/421) (classification)
BAC = 0.660686 (Sens = 0.333333, Spec = 0.988038)
training with -t 0 -g 0.000000e+00 -c 5.623413e+03 -w-1 1 -w1 9.592308e+01 -q -e 1.000000e-03
training performance:
Accuracy = 100% (1260/1260) (classification)
BAC = 1 (Sens = 1, Spec = 1)
testing performance:
Accuracy = 97.1963% (416/428) (classification)
BAC = 0.492891 (Sens = 0, Spec = 0.985782)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.999401
Average generalization performance after CV: 0.755638

CV with -t 0 -g 0.000000e+00 -c 1.000000e+05 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.000000e+05 -w-1 1 -w1 9.638462e+01 -q -e 1.000000e-03
training performance:
Accuracy = 100% (1266/1266) (classification)
BAC = 1 (Sens = 1, Spec = 1)
testing performance:
Accuracy = 97.1564% (410/422) (classification)
BAC = 0.657051 (Sens = 0.333333, Spec = 0.980769)
training with -t 0 -g 0.000000e+00 -c 1.000000e+05 -w-1 1 -w1 7.875000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.7649% (1273/1276) (classification)
BAC = 0.99881 (Sens = 1, Spec = 0.997619)
testing performance:
Accuracy = 98.7864% (407/412) (classification)
BAC = 0.662999 (Sens = 0.333333, Spec = 0.992665)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.999702
Average generalization performance after CV: 0.830013

training with best hyperparameters (CV gen prediction: 0.87814)
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 8.805263e+01 -q -e 1.000000e-03
training performance:
Accuracy = 87.9433% (1488/1692) (classification)
BAC = 0.939032 (Sens = 1, Spec = 0.878063)

3. run of generalization assessment CV -- testing
Accuracy = 88.2867% (505/572) (classification)
BAC = 0.870164 (Sens = 0.857143, Spec = 0.883186)

4. run of generalization assessment CV -- training

grid search for best hyperparameters


CV with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 9.364286e+01 -q -e 1.000000e-03
training performance:
Accuracy = 86.3396% (1144/1325) (classification)
BAC = 0.82497 (Sens = 0.785714, Spec = 0.864226)
testing performance:
Accuracy = 80.9524% (289/357) (classification)
BAC = 0.903409 (Sens = 1, Spec = 0.806818)
training with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 8.535714e+01 -q -e 1.000000e-03
training performance:
Accuracy = 83.3747% (1008/1209) (classification)
BAC = 0.845308 (Sens = 0.857143, Spec = 0.833473)
testing performance:
Accuracy = 86.4693% (409/473) (classification)
BAC = 0.931624 (Sens = 1, Spec = 0.863248)
training with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 7.706667e+01 -q -e 1.000000e-03
training performance:
Accuracy = 79.5901% (932/1171) (classification)
BAC = 0.830825 (Sens = 0.866667, Spec = 0.794983)
testing performance:
Accuracy = 82.9746% (424/511) (classification)
BAC = 0.790187 (Sens = 0.75, Spec = 0.830375)
training with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 9.478571e+01 -q -e 1.000000e-03
training performance:
Accuracy = 86.95% (1166/1341) (classification)
BAC = 0.898724 (Sens = 0.928571, Spec = 0.868877)
testing performance:
Accuracy = 84.4575% (288/341) (classification)
BAC = 0.625595 (Sens = 0.4, Spec = 0.85119)
Average training performance after CV: 0.849957
Average generalization performance after CV: 0.812704

CV with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 9.938462e+01 -q -e 1.000000e-03
training performance:
Accuracy = 90.9579% (1187/1305) (classification)
BAC = 0.954334 (Sens = 1, Spec = 0.908669)
testing performance:
Accuracy = 92.0424% (347/377) (classification)
BAC = 0.713612 (Sens = 0.5, Spec = 0.927224)
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 7.525000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 84.3443% (1029/1220) (classification)
BAC = 0.920681 (Sens = 1, Spec = 0.841362)
testing performance:
Accuracy = 86.3636% (399/462) (classification)
BAC = 0.931373 (Sens = 1, Spec = 0.862745)
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 8.592857e+01 -q -e 1.000000e-03
training performance:
Accuracy = 87.1816% (1061/1217) (classification)
BAC = 0.935162 (Sens = 1, Spec = 0.870324)
testing performance:
Accuracy = 87.957% (409/465) (classification)
BAC = 0.93913 (Sens = 1, Spec = 0.878261)
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 9.214286e+01 -q -e 1.000000e-03
training performance:
Accuracy = 86.1196% (1123/1304) (classification)
BAC = 0.929845 (Sens = 1, Spec = 0.85969)
testing performance:
Accuracy = 81.4815% (308/378) (classification)
BAC = 0.906166 (Sens = 1, Spec = 0.812332)
Average training performance after CV: 0.935006
Average generalization performance after CV: 0.87257

CV with -t 0 -g 0.000000e+00 -c 3.162278e-03 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 3.162278e-03 -w-1 1 -w1 9.014286e+01 -q -e 1.000000e-03
training performance:
Accuracy = 95.8464% (1223/1276) (classification)
BAC = 0.979002 (Sens = 1, Spec = 0.958003)
testing performance:
Accuracy = 92.8571% (377/406) (classification)
BAC = 0.766334 (Sens = 0.6, Spec = 0.932668)
training with -t 0 -g 0.000000e+00 -c 3.162278e-03 -w-1 1 -w1 7.900000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 95.9375% (1228/1280) (classification)
BAC = 0.97943 (Sens = 1, Spec = 0.958861)
testing performance:
Accuracy = 94.2786% (379/402) (classification)
BAC = 0.805764 (Sens = 0.666667, Spec = 0.944862)
training with -t 0 -g 0.000000e+00 -c 3.162278e-03 -w-1 1 -w1 9.958333e+01 -q -e 1.000000e-03
training performance:
Accuracy = 96.3546% (1163/1207) (classification)
BAC = 0.98159 (Sens = 1, Spec = 0.96318)
testing performance:
Accuracy = 95.1579% (452/475) (classification)
BAC = 0.764347 (Sens = 0.571429, Spec = 0.957265)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.985005
Average generalization performance after CV: 0.834111

CV with -t 0 -g 0.000000e+00 -c 5.623413e-02 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 5.623413e-02 -w-1 1 -w1 1.001667e+02 -q -e 1.000000e-03
training performance:
Accuracy = 99.0115% (1202/1214) (classification)
BAC = 0.995008 (Sens = 1, Spec = 0.990017)
testing performance:
Accuracy = 97.2222% (455/468) (classification)
BAC = 0.704524 (Sens = 0.428571, Spec = 0.980477)
training with -t 0 -g 0.000000e+00 -c 5.623413e-02 -w-1 1 -w1 7.875000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 98.5893% (1258/1276) (classification)
BAC = 0.992857 (Sens = 1, Spec = 0.985714)
testing performance:
Accuracy = 98.2759% (399/406) (classification)
BAC = 0.660463 (Sens = 0.333333, Spec = 0.987593)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.996966
Average generalization performance after CV: 0.841247

CV with -t 0 -g 0.000000e+00 -c 1.000000e+00 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.000000e+00 -w-1 1 -w1 8.373333e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.764% (1268/1271) (classification)
BAC = 0.998806 (Sens = 1, Spec = 0.997611)
testing performance:
Accuracy = 98.0535% (403/411) (classification)
BAC = 0.618857 (Sens = 0.25, Spec = 0.987715)
training with -t 0 -g 0.000000e+00 -c 1.000000e+00 -w-1 1 -w1 9.776923e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.8442% (1282/1284) (classification)
BAC = 0.999213 (Sens = 1, Spec = 0.998426)
testing performance:
Accuracy = 97.4874% (388/398) (classification)
BAC = 0.659014 (Sens = 0.333333, Spec = 0.984694)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.999505
Average generalization performance after CV: 0.819468

CV with -t 0 -g 0.000000e+00 -c 1.778279e+01 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.778279e+01 -w-1 1 -w1 9.050000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.8439% (1279/1281) (classification)
BAC = 0.999211 (Sens = 1, Spec = 0.998421)
testing performance:
Accuracy = 97.5062% (391/401) (classification)
BAC = 0.592424 (Sens = 0.2, Spec = 0.984848)
training with -t 0 -g 0.000000e+00 -c 1.778279e+01 -w-1 1 -w1 9.383333e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.8243% (1136/1138) (classification)
BAC = 0.999112 (Sens = 1, Spec = 0.998224)
testing performance:
Accuracy = 98.1618% (534/544) (classification)
BAC = 0.567704 (Sens = 0.142857, Spec = 0.992551)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.999581
Average generalization performance after CV: 0.790032

CV with -t 0 -g 0.000000e+00 -c 3.162278e+02 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 3.162278e+02 -w-1 1 -w1 9.515385e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.84% (1248/1250) (classification)
BAC = 0.999192 (Sens = 1, Spec = 0.998383)
testing performance:
Accuracy = 97.2222% (420/432) (classification)
BAC = 0.492958 (Sens = 0, Spec = 0.985915)
training with -t 0 -g 0.000000e+00 -c 3.162278e+02 -w-1 1 -w1 8.400000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.9216% (1274/1275) (classification)
BAC = 0.999603 (Sens = 1, Spec = 0.999206)
testing performance:
Accuracy = 98.5258% (401/407) (classification)
BAC = 0.745037 (Sens = 0.5, Spec = 0.990074)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.999699
Average generalization performance after CV: 0.809499

CV with -t 0 -g 0.000000e+00 -c 5.623413e+03 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 5.623413e+03 -w-1 1 -w1 9.250000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 100% (1309/1309) (classification)
BAC = 1 (Sens = 1, Spec = 1)
testing performance:
Accuracy = 97.0509% (362/373) (classification)
BAC = 0.491848 (Sens = 0, Spec = 0.983696)
training with -t 0 -g 0.000000e+00 -c 5.623413e+03 -w-1 1 -w1 8.784615e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.8268% (1153/1155) (classification)
BAC = 0.999124 (Sens = 1, Spec = 0.998249)
testing performance:
Accuracy = 98.2922% (518/527) (classification)
BAC = 0.579495 (Sens = 0.166667, Spec = 0.992322)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.999781
Average generalization performance after CV: 0.767836

CV with -t 0 -g 0.000000e+00 -c 1.000000e+05 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.000000e+05 -w-1 1 -w1 8.466667e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.7665% (1282/1285) (classification)
BAC = 0.998819 (Sens = 1, Spec = 0.997638)
testing performance:
Accuracy = 98.4887% (391/397) (classification)
BAC = 0.621183 (Sens = 0.25, Spec = 0.992366)
training with -t 0 -g 0.000000e+00 -c 1.000000e+05 -w-1 1 -w1 8.846154e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.914% (1162/1163) (classification)
BAC = 0.999565 (Sens = 1, Spec = 0.99913)
testing performance:
Accuracy = 95.9538% (498/519) (classification)
BAC = 0.650097 (Sens = 0.333333, Spec = 0.966862)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.999596
Average generalization performance after CV: 0.81782

training with best hyperparameters (CV gen prediction: 0.87257)
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 8.752632e+01 -q -e 1.000000e-03
training performance:
Accuracy = 87.1581% (1466/1682) (classification)
BAC = 0.935057 (Sens = 1, Spec = 0.870114)

4. run of generalization assessment CV -- testing
Accuracy = 84.8797% (494/582) (classification)
BAC = 0.852919 (Sens = 0.857143, Spec = 0.848696)

Training perfomance as evaluated by 4-fold CV is 0.938497 +-0.00365259

Generalization perfomance as evaluated by 4-fold CV is 0.898954 +-0.0438699
Prediction of CV was 0.869702 +-0.0210009

training model on whole dataset
grid search for best hyperparameters


CV with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 8.530000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 84.0093% (1450/1726) (classification)
BAC = 0.795574 (Sens = 0.75, Spec = 0.841149)
testing performance:
Accuracy = 84.5725% (455/538) (classification)
BAC = 0.839599 (Sens = 0.833333, Spec = 0.845865)
training with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 8.447368e+01 -q -e 1.000000e-03
training performance:
Accuracy = 81.2808% (1320/1624) (classification)
BAC = 0.801279 (Sens = 0.789474, Spec = 0.813084)
testing performance:
Accuracy = 82.5% (528/640) (classification)
BAC = 0.840894 (Sens = 0.857143, Spec = 0.824645)
training with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 8.505000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 77.0482% (1326/1721) (classification)
BAC = 0.859186 (Sens = 0.95, Spec = 0.768372)
testing performance:
Accuracy = 79.3738% (431/543) (classification)
BAC = 0.730912 (Sens = 0.666667, Spec = 0.795158)
training with -t 0 -g 0.000000e+00 -c 1.000000e-05 -w-1 1 -w1 8.957895e+01 -q -e 1.000000e-03
training performance:
Accuracy = 85.8803% (1478/1721) (classification)
BAC = 0.798503 (Sens = 0.736842, Spec = 0.860165)
testing performance:
Accuracy = 84.5304% (459/543) (classification)
BAC = 0.851146 (Sens = 0.857143, Spec = 0.845149)
Average training performance after CV: 0.813636
Average generalization performance after CV: 0.815638

CV with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 9.272222e+01 -q -e 1.000000e-03
training performance:
Accuracy = 91.642% (1546/1687) (classification)
BAC = 0.957759 (Sens = 1, Spec = 0.915518)
testing performance:
Accuracy = 93.9341% (542/577) (classification)
BAC = 0.78438 (Sens = 0.625, Spec = 0.943761)
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 8.119048e+01 -q -e 1.000000e-03
training performance:
Accuracy = 88.2387% (1523/1726) (classification)
BAC = 0.940469 (Sens = 1, Spec = 0.880938)
testing performance:
Accuracy = 83.2714% (448/538) (classification)
BAC = 0.915572 (Sens = 1, Spec = 0.831144)
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 7.900000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 85.0595% (1429/1680) (classification)
BAC = 0.924352 (Sens = 1, Spec = 0.848704)
testing performance:
Accuracy = 88.8699% (519/584) (classification)
BAC = 0.943869 (Sens = 1, Spec = 0.887737)
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 9.338889e+01 -q -e 1.000000e-03
training performance:
Accuracy = 87.8164% (1492/1699) (classification)
BAC = 0.93843 (Sens = 1, Spec = 0.876859)
testing performance:
Accuracy = 85.3097% (482/565) (classification)
BAC = 0.925494 (Sens = 1, Spec = 0.850987)
Average training performance after CV: 0.940252
Average generalization performance after CV: 0.892329

CV with -t 0 -g 0.000000e+00 -c 3.162278e-03 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 3.162278e-03 -w-1 1 -w1 7.745455e+01 -q -e 1.000000e-03
training performance:
Accuracy = 94.3801% (1629/1726) (classification)
BAC = 0.971538 (Sens = 1, Spec = 0.943075)
testing performance:
Accuracy = 94.052% (506/538) (classification)
BAC = 0.845974 (Sens = 0.75, Spec = 0.941948)
training with -t 0 -g 0.000000e+00 -c 3.162278e-03 -w-1 1 -w1 9.229412e+01 -q -e 1.000000e-03
training performance:
Accuracy = 95.6494% (1517/1586) (classification)
BAC = 0.978011 (Sens = 1, Spec = 0.956023)
testing performance:
Accuracy = 95.4277% (647/678) (classification)
BAC = 0.812407 (Sens = 0.666667, Spec = 0.958146)
training with -t 0 -g 0.000000e+00 -c 3.162278e-03 -w-1 1 -w1 8.973684e+01 -q -e 1.000000e-03
training performance:
Accuracy = 95.8817% (1653/1724) (classification)
BAC = 0.979179 (Sens = 1, Spec = 0.958358)
testing performance:
Accuracy = 94.2593% (509/540) (classification)
BAC = 0.759448 (Sens = 0.571429, Spec = 0.947467)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.982182
Average generalization performance after CV: 0.854457

CV with -t 0 -g 0.000000e+00 -c 5.623413e-02 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 5.623413e-02 -w-1 1 -w1 7.690476e+01 -q -e 1.000000e-03
training performance:
Accuracy = 97.9218% (1602/1636) (classification)
BAC = 0.989474 (Sens = 1, Spec = 0.978947)
testing performance:
Accuracy = 96.6561% (607/628) (classification)
BAC = 0.883949 (Sens = 0.8, Spec = 0.967897)
training with -t 0 -g 0.000000e+00 -c 5.623413e-02 -w-1 1 -w1 9.377778e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.3552% (1695/1706) (classification)
BAC = 0.996742 (Sens = 1, Spec = 0.993483)
testing performance:
Accuracy = 97.1326% (542/558) (classification)
BAC = 0.492727 (Sens = 0, Spec = 0.985455)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.996554
Average generalization performance after CV: 0.844169

CV with -t 0 -g 0.000000e+00 -c 1.000000e+00 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.000000e+00 -w-1 1 -w1 9.047368e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.5972% (1731/1738) (classification)
BAC = 0.997964 (Sens = 1, Spec = 0.995928)
testing performance:
Accuracy = 96.7681% (509/526) (classification)
BAC = 0.701762 (Sens = 0.428571, Spec = 0.974952)
training with -t 0 -g 0.000000e+00 -c 1.000000e+00 -w-1 1 -w1 8.463158e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.5698% (1620/1627) (classification)
BAC = 0.997823 (Sens = 1, Spec = 0.995647)
testing performance:
Accuracy = 97.3312% (620/637) (classification)
BAC = 0.562698 (Sens = 0.142857, Spec = 0.98254)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.998947
Average generalization performance after CV: 0.816115

CV with -t 0 -g 0.000000e+00 -c 1.778279e+01 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.778279e+01 -w-1 1 -w1 9.163158e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.7159% (1755/1760) (classification)
BAC = 0.998564 (Sens = 1, Spec = 0.997128)
testing performance:
Accuracy = 95.8333% (483/504) (classification)
BAC = 0.485915 (Sens = 0, Spec = 0.971831)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.999641
Average generalization performance after CV: 0.871479

CV with -t 0 -g 0.000000e+00 -c 3.162278e+02 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 3.162278e+02 -w-1 1 -w1 8.966667e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.6936% (1627/1632) (classification)
BAC = 0.998451 (Sens = 1, Spec = 0.996902)
testing performance:
Accuracy = 97.3101% (615/632) (classification)
BAC = 0.616186 (Sens = 0.25, Spec = 0.982372)
training with -t 0 -g 0.000000e+00 -c 3.162278e+02 -w-1 1 -w1 8.023810e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.6483% (1700/1706) (classification)
BAC = 0.99822 (Sens = 1, Spec = 0.996439)
testing performance:
Accuracy = 97.1326% (542/558) (classification)
BAC = 0.490054 (Sens = 0, Spec = 0.980108)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.999168
Average generalization performance after CV: 0.77656

CV with -t 0 -g 0.000000e+00 -c 5.623413e+03 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 5.623413e+03 -w-1 1 -w1 7.904762e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.5241% (1673/1681) (classification)
BAC = 0.99759 (Sens = 1, Spec = 0.995181)
testing performance:
Accuracy = 97.4271% (568/583) (classification)
BAC = 0.689619 (Sens = 0.4, Spec = 0.979239)
training with -t 0 -g 0.000000e+00 -c 5.623413e+03 -w-1 1 -w1 8.395000e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.5291% (1691/1699) (classification)
BAC = 0.997618 (Sens = 1, Spec = 0.995235)
testing performance:
Accuracy = 98.2301% (555/565) (classification)
BAC = 0.578861 (Sens = 0.166667, Spec = 0.991055)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.998802
Average generalization performance after CV: 0.81712

CV with -t 0 -g 0.000000e+00 -c 1.000000e+05 -w-1 1 -w1 1 -q -e 1.000000e-03...splitting data into training/test folds.
........
training with -t 0 -g 0.000000e+00 -c 1.000000e+05 -w-1 1 -w1 9.027778e+01 -q -e 1.000000e-03
training performance:
Accuracy = 99.6957% (1638/1643) (classification)
BAC = 0.998462 (Sens = 1, Spec = 0.996923)
testing performance:
Accuracy = 95.6522% (594/621) (classification)
BAC = 0.484502 (Sens = 0, Spec = 0.969005)
CV run cannot reach best value any more, aborting
Average training performance after CV: 0.999615
Average generalization performance after CV: 0.871126

training with best hyperparameters (CV gen prediction: 0.892329)
training with -t 0 -g 0.000000e+00 -c 1.778279e-04 -w-1 1 -w1 8.607692e+01 -q -e 1.000000e-03
training performance:
Accuracy = 88.0742% (1994/2264) (classification)
BAC = 0.939678 (Sens = 1, Spec = 0.879357)

modelhashes = 

    'wp2hash: eb547dd9ed7ae4f4163db16b79fca818'
    'blockdatahash: 7a180c1876a00a3f70b5a184c2cd2e1c'
    'labelhash: 22112f21cb8342ed72d7ed90c0408841'
    'featureshash: 288c1b417cfe366c5c496810f015e7db'
    'splitdatahash: 295eec4ff06feeeda05dd9a49f99e9c2'
    'modelhash: 00c0c356871969599a0c45266e82e1ec'

