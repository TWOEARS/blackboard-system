%% Basierend auf einer TeXnicCenter-Vorlage von Mark Müller
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Wählen Sie die Optionen aus, indem Sie % vor der Option entfernen  
% Dokumentation des KOMA-Script-Packets: scrguide

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Optionen zum Layout des Artikels                                  %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[%
%a5paper,							% alle weiteren Papierformat einstellbar
%landscape,						% Querformat
%10pt,								% Schriftgröße (12pt, 11pt (Standard))
%BCOR1cm,							% Bindekorrektur, bspw. 1 cm
%DIVcalc,							% führt die Satzspiegelberechnung neu aus
%											  s. scrguide 2.4
%twoside,							% Doppelseiten
%twocolumn,						% zweispaltiger Satz
%halfparskip*,				% Absatzformatierung s. scrguide 3.1
%headsepline,					% Trennline zum Seitenkopf	
%footsepline,					% Trennline zum Seitenfuß
%titlepage,						% Titelei auf eigener Seite
%normalheadings,			% Überschriften etwas kleiner (smallheadings)
%idxtotoc,						% Index im Inhaltsverzeichnis
%liststotoc,					% Abb.- und Tab.verzeichnis im Inhalt
%bibtotoc,						% Literaturverzeichnis im Inhalt
%abstracton,					% Überschrift über der Zusammenfassung an	
%leqno,   						% Nummerierung von Gleichungen links
%fleqn,								% Ausgabe von Gleichungen linksbündig
%draft								% überlangen Zeilen in Ausgabe gekennzeichnet
]
{scrartcl}


\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage[ansinew]{inputenc}

\usepackage{lmodern} 

\usepackage{SIunits}

\usepackage[colorlinks = true, citecolor = blue]{hyperref}

\usepackage{natbib}
\bibliographystyle{jasaauthyear}


\begin{document}

\pagestyle{empty} 

\title{Framework for ITD-based sound source localization in complex acoustic environments}
\author{Tobias May and Nicolas Le Goff}


\maketitle 				


\section{Introduction}
One of the most important physical cues that enables human sound source localization are the interaural time differences (ITDs) and interaural level differences (ILDs) between the left and the right ear signals. The purpose of this framework is to develop algorithms that are able to find the azimuth angle of multiple competing speech sources relative to an artificial head. The first two very basic algorithms only exploit estimates of the ITD. 

The relation between a particular sound source azimuth and its corresponding ITD depends on the size and the geometry of the artificial head. Therefore, a mapping must be employed to relate the estimated ITD to its corresponding azimuth position. The mapping function is obtained during an initial \emph{calibration} stage, in which the azimuth of a single sound source in anechoic conditions (no reflections) is systematically varied across the azimuth range of interest (e.g. $\left[-90\,\degree, 90\,\degree\right]$), and the resulting ITD is measured. 


Given a binaural signal, the azimuth of a sound source is localized by performing the following two steps: first, the ITD is estimated by a correlation analysis. More specifically, the ITD is assumed to be reflected by the lag that corresponds to the most prominent peak in the cross-correlation function. In the second step, the observed ITD is related to its corresponding sound source azimuth by applying the mapping function that has been created during the calibration stage. So far, two basic sound source localization approaches are implemented:

\begin{enumerate}
	\item The broadband approach (\verb#estimate_Azimuth_Broadband.m#):\vskip0.5ex Sound source localization is performed in the ``audio domain'' by computing the cross-correlation function over short time frames of $20\,\milli\second$ (\verb#winSec = 20E-3#). The resulting 2-dimensional cross-correlation function \verb#CCF#, which is a function of the number of time lags (ITDs) and the number of frames (\verb#nLags x nFrames#), is mapped onto an azimuth grid (\verb#nAzimuth x nFrames#). The required mapping function is computed by \verb#calibrate_ITD_Broadband.m#. Then, this new CCF is integrated across all time frames and the most prominent peaks are assumed to reflect the estimated sound source azimuth positions.
	
	\item The subband approach (\verb#estimate_Azimuth_Subband.m#:):\vskip0.5ex A peripheral auditory processing stage is included, which decomposes the input signals into individual frequency channels using a gammatone filterbank (\verb#gammaFB.m#). The center frequencies are equally spaced on the equivalent rectangular bandwidth (ERB)-rate scale between \verb#fLowHz = 100# and \verb#fHighHz = 12000# $\hertz$.	Sound source localization is performed in the ``auditory domain'' by computing the cross-correlation function for each subband over short windows of $20\,\milli\second$ (\verb#winSec = 20E-3#). The resulting 3-dimensional cross-correlation function \verb#CCF#, which is a function of the number of lags, subbands and frames (\verb#nLags x nSubbands x nFrames#) is mapped onto an azimuth grid (\verb#nAzimuth x nSubbands x nFrames#). The required mapping function is computed by \verb#calibrate_ITD_Subband.m#. This mapping is performed for each subband separately. Then, this new CCF is integrated across all subbands and frames and the most prominent peaks are assumed to reflect the estimated sound source azimuth positions. This implementation is a simplified version of the algorithm described in~\cite{PalomakiBrownWang04}.	
\end{enumerate}


The estimation of the ITD, and accordingly, its sound source azimuth can be reliably obtained for one sound source in anechoic condition. However, in more complex acoustic environments, the direct sound from multiple sources that are positioned at different azimuth angles and room reflections overlap, thus changing the interaural time differences at the receiver. Therefore, more sophisticated localization approaches will be developed and implemented that also exploit the ILD cue. A general overview about binaural sound source localization techniques can be found in~\cite{MayvandeParKohlrausch13}, which is supplied in the literature folder. The modular structure allows to test different modifications and the evaluate the benefit of individual processing stages.


\section{Experimental framework}
Call the main script \verb#localization_experiment.m# in order to perform one run of the localization experiment. During the experiment, a predefined number of speech sources are randomly positioned at unknown azimuth angles relative to the receiver. The amount of reverberation can be changed during each run of the localization experiment by selecting a particular set of binaural room impulse responses (BRIRs). The localization accuracy of both approaches is measured by computing the percentage of correctly localized sources (\verb#pc1# and \verb#pc2#) within a predefined error threshold, as well as the root mean square error of the correctly localized soures in comparison to their true azimuth (\verb#rmse1# and \verb#rmse2#). A summary of the settings that can be controlled in the header of the main script is given below:

\begin{enumerate}
	\item Algorithm settings
	
	\begin{itemize}
		\item \verb#fs# controls the sampling frequency in $\hertz$ 
		\item \verb#fLowHz# and \verb#fHighHz# define the lowest and the highest center frequency of the gammatone filterbank
		\item \verb#winSec# determines the frame size for the cross-correlation analysis 
	\end{itemize}
	
	\item Acoustic settings
	
	\begin{itemize}
		\item \verb#nSpeakers# specifies the number of competing speech sources that are randomly placed at unknown azimuth angles
		\item \verb#minDistance# defines the minimum angular distance between competing sources
		\item \verb#rooms# is a list of BRIRs that is used to spatialize the speech sources. An overview of all five rooms is given in Tab.~\ref{tab:BRIRs}. The acoustic properties of the different rooms are characterized by the reverberation time $T_{\mathrm{60}}$ and the direct-to-reverberant ratio (DRR).		
	\end{itemize}
	
		\item Evaluation settings
	
		\begin{itemize}
		\item \verb#nMixtures# defines the number of binaural signals created for each room (\verb#rooms#)
		\item \verb#thresDeg# controls the absolute error boundary in degree used to compute the percentage of correctly localized sound sources
		\item \verb#bVisualize# if \verb#true#, the output of both localization approaches (\verb#Broadband# and \verb#Subband#) is plotted in two individual figures for each binaural signal. You can turn off the visualization by setting \verb#bVisualize = false# for a faster execution of the experiment.
				
	\end{itemize}
		
\end{enumerate}

\begin{table}[!t]
\caption{Acoustic properties of different BRIRs~\citep{HummersoneMasonBrookes10}.} 
\label{tab:BRIRs}
\centering
\begin{tabular}{|l|l|c|c|}
\hline
Name & Room description & $T_{\mathrm{60}}\,(\second)$ & DRR $(\deci\bel)$ \\
\hline
\hline
\verb#'SURREY_A'# & Anechoic condition                      & 0.0 & $\infty$ \\
\verb#'SURREY_ROOM_A'# & Medium-sized office                & 0.32 & 6.09 \\
\verb#'SURREY_ROOM_B'# & Medium–small class room            & 0.47 & 5.31 \\
\verb#'SURREY_ROOM_C'# & Large cinema–style lecture theater & 0.68 & 8.82 \\
\verb#'SURREY_ROOM_D'# & Medium–large sized seminar space   & 0.89 & 6.12 \\
\hline
\end{tabular}
\end{table} 







\bibliography{References}	
\end{document}
